{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import lightning as L\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "from dataset_new import SentinelDataset\n",
    "from plotting import plot_patch, plot_coords_distribution\n",
    "from utils import get_dataset_stats\n",
    "from transforms import TargetNormalize\n",
    "from model import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "dataset = SentinelDataset(\n",
    "    \"../data/samples/samples_S2S5P_2018_2020_eea.csv\",\n",
    "    \"../data/sentinel-2-eea\",\n",
    "    n_patches=4,\n",
    "    patch_size=256,\n",
    "    pre_load=False,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "dataset_train, dataset_val, dataset_test = random_split(dataset, [0.70, 0.15, 0.15], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataloaders\n",
    "batch_size = 16\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=9, persistent_workers=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, num_workers=9, persistent_workers=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics on training dataset\n",
    "# stats_train = get_dataset_stats(dataset_train)\n",
    "stats_train = {\n",
    "    \"band_means\": np.array(\n",
    "        [\n",
    "            945.33649575,\n",
    "            883.58855028,\n",
    "            668.64586693,\n",
    "            2310.99404037,\n",
    "            1278.33074938,\n",
    "            1972.10197878,\n",
    "            2223.2728232,\n",
    "            2376.76157865,\n",
    "            2052.98432657,\n",
    "            1548.28168202,\n",
    "            562.55420622,\n",
    "            2380.19286924,\n",
    "        ]\n",
    "    ),\n",
    "    \"band_stds\": np.array(\n",
    "        [\n",
    "            530.8678687,\n",
    "            432.87239649,\n",
    "            405.77116269,\n",
    "            814.35871003,\n",
    "            431.60858877,\n",
    "            556.86715088,\n",
    "            659.36416425,\n",
    "            705.73567854,\n",
    "            566.20799311,\n",
    "            555.80665277,\n",
    "            216.07139462,\n",
    "            564.50506163,\n",
    "        ]\n",
    "    ),\n",
    "    \"no2_mean\": 20.683807196968576,\n",
    "    \"no2_std\": 11.520772291494632,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create normalizers for bands and NO2 measurements\n",
    "band_normalize = Normalize(stats_train[\"band_means\"], stats_train[\"band_stds\"])\n",
    "no2_normalize = TargetNormalize(stats_train[\"no2_mean\"], stats_train[\"no2_std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pytorch lightning model\n",
    "\n",
    "class Model(L.LightningModule):\n",
    "    def __init__(self, lr=1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set model\n",
    "        self.model = UNet()\n",
    "\n",
    "        # Set hyperparameters\n",
    "        self.loss = MSELoss()\n",
    "        self.mae = L1Loss()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, mae = self._step(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_mae\", mae)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, mae = self._step(batch)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_mae\", mae)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, mae = self._step(batch)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_mae\", mae)\n",
    "        return loss\n",
    "    \n",
    "    def _step(self, batch):\n",
    "        # Unpack batch\n",
    "        patches, measurements, coords = batch\n",
    "\n",
    "        # Normalize band and measurement data\n",
    "        patches_norm = band_normalize(patches)\n",
    "        measurements_norm = no2_normalize(measurements)\n",
    "\n",
    "        # Get normalized predictions\n",
    "        predictions_norm = self.model(patches_norm)\n",
    "\n",
    "        # Extract values in coordinate location\n",
    "        target_values_norm = torch.diag(predictions_norm[:, 0, coords[0], coords[1]])\n",
    "\n",
    "        # Compute loss on normalized data\n",
    "        loss = self.loss(target_values_norm, measurements_norm)\n",
    "\n",
    "        # Compute Mean Absolute Error on unnormalized data\n",
    "        target_values = no2_normalize.revert(target_values_norm)\n",
    "        mae = self.mae(target_values, measurements)\n",
    "\n",
    "        return loss, mae\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logger for weights & biases\n",
    "wandb_logger = WandbLogger(project=\"IMP-2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrubengaviles\u001b[0m (\u001b[33mimp-2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20231114_193218-zeyzfwq7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imp-2023/IMP-2023/runs/zeyzfwq7' target=\"_blank\">effortless-monkey-7</a></strong> to <a href='https://wandb.ai/imp-2023/IMP-2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imp-2023/IMP-2023' target=\"_blank\">https://wandb.ai/imp-2023/IMP-2023</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imp-2023/IMP-2023/runs/zeyzfwq7' target=\"_blank\">https://wandb.ai/imp-2023/IMP-2023/runs/zeyzfwq7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | UNet    | 31.0 M\n",
      "1 | loss  | MSELoss | 0     \n",
      "2 | mae   | L1Loss  | 0     \n",
      "----------------------------------\n",
      "31.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 M    Total params\n",
      "124.148   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 1/100 [00:21<35:58,  0.05it/s, v_num=fwq7]       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rubengonzalez/miniconda3/envs/imp/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trainer = L.Trainer(limit_train_batches=100, max_epochs=1, logger=wandb_logger, log_every_n_steps=1, val_check_interval=20)\n",
    "trainer.fit(model=model, train_dataloaders=dataloader_train, val_dataloaders=dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
